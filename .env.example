CURRENT_ENV=development
DOLLAR=$
LOCALHOST=127.0.0.1

# globals
APP_NAME=sortes # name of the app
MAX_LABEL_LENGTH=200 # maximum number of characters for a document label
MAX_DATA_LENGTH=50000 # maximum number of characters a document can contain
MAX_SEQ_LENGTH=500 # the document is truncated into sequences to feed into the transformer this defines the maximum character length. Must be less or equal the hyper parameter of the model in use
MAX_NUM_OF_SEQ=100 # maximum number of sequences (MAX_DATA_LENGTH / MAX_SEQ_LENGTH)
DATA_SEQ_STRIDE=350 # stride value to compensate for the truncation resulting from max sequencing


# data related
CORPUS_DIR_PATH=${PWD}/corpus/raw # directory location of the corpus
CORPUS_OUTPUT_FILE_PATH=${PWD}/corpus/processed/000-rank-corpus # file location of the output after cleaning with the `sortes cli app` this is a `c struct` pack into a binary file [C STRUCT]


# ml related
HF_HUB_OFFLINE=TRUE # disable hugging face from sending http requests
HF_HOME=${PWD}/cache # dir location for hugging face to store data

PASSAGE_RANK_MODEL_DIR_PATH=${PWD}/models/msmarco-distilbert-base-tas-b # dir location for the passage ranking model
PASSAGE_RANK_MODEL_LABELS_PY_LIST_PATH=${PWD}/cache/msmarco-distilbert-base-tas-b/docs.labels # file location for a python list of labels ordered respectively to the tensor outputs from the model
PASSAGE_RANK_MODEL_OUTPUT_PT_TENSOR_PATH=${PWD}/cache/msmarco-distilbert-base-tas-b/docs.output.pt.tensor # file location for the `pytorch` tensors output generated after passing the corpus throug the passage rank model [PYTHON PICKLE]

EXTRACTIVE_Q_A_MODEL_DIR_PATH=${PWD}/models/tinyroberta-squad2 # dir location for the extractive question and answer model
EXTRACTIVE_Q_A_MODEL_CONTEXTS_PY_LIST_PATH=${PWD}/cache/tinyroberta-squad2/docs.contexts # file location for a python list of contexts
EXTRACTIVE_Q_A_MODEL_OUTPUT_PT_TENSOR_PATH=${PWD}/cache/tinyroberta-squad2/docs.output.pt.tensor # file location for the `pytorch` tensors output generated after passing the corpus throug the extractive Q&A model [PYTHON PICKLE]

SUMMARISATION_MODEL_DIR_PATH=${PWD}/models/bart-large-cnn-samsum # dir location for the summarisation model


# c related


# php related


# python related
PYTHON_ENV=${CURRENT_ENV}
PYTHONUNBUFFERED=1


# slack bot related
SLACK_BOT_TOKEN=
SLACK_SIGNING_SECRET=
SLACK_BOT_DEV_TOKEN=
SLACK_SIGNING_DEV_SECRET=
SLACK_API_DEV_PORT=5000


# agent api related
AGENT_API_DEV_PORT=5001


# ui related
UI_DEV_PORT=5002

